{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "fake_news.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "477boDLrwWRz"
      },
      "source": [
        "## Fake News Classification\n",
        "\n",
        "Solution: [Universal Sentence Encoder (USE) for English](https://www.aclweb.org/anthology/D18-2029)\n",
        "\n",
        "This [blog post](https://towardsdatascience.com/using-use-universal-sentence-encoder-to-detect-fake-news-dfc02dc32ae9) reaches ~ 90% accuracy with universal encoder from tf hub. But can we reach the same results with a simple encoder ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_u6t19vwdcV",
        "outputId": "bd29e13d-59cd-4483-f88e-74260fb5d53b"
      },
      "source": [
        "!pip install -U pipenv && pipenv install --dev\n",
        "!pip install encoder"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pipenv in /usr/local/lib/python3.7/dist-packages (2021.11.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pipenv) (2021.10.8)\n",
            "Requirement already satisfied: setuptools>=36.2.1 in /usr/local/lib/python3.7/dist-packages (from pipenv) (57.4.0)\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from pipenv) (20.10.0)\n",
            "Requirement already satisfied: pip>=18.0 in /usr/local/lib/python3.7/dist-packages (from pipenv) (21.1.3)\n",
            "Requirement already satisfied: virtualenv-clone>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from pipenv) (0.5.7)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (2.4.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (0.3.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (4.8.2)\n",
            "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (1.1.1)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (3.3.2)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv->pipenv) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv->pipenv) (3.10.0.2)\n",
            "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (a65489)...\u001b[39m\u001b[22m\n",
            "  🐍   \u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m 0/0 — \u001b[30m\u001b[22m00:00:00\u001b[39m\u001b[22m\n",
            "To activate this project's virtualenv, run \u001b[33m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
            "Alternatively, run a command inside the virtualenv with \u001b[33m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
            "\u001b[0mRequirement already satisfied: encoder in /usr/local/lib/python3.7/dist-packages (1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3G5pJGExzZj",
        "outputId": "854c0d0d-dd85-4eae-d519-48a39c7e2c91"
      },
      "source": [
        "! pip install fasttext"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.8.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt-UqoPdyG28",
        "outputId": "c243f247-2504-491f-ae90-f63cb8cffa64"
      },
      "source": [
        "! pip install contractions"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.55)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeZo197MyNF0",
        "outputId": "036c41b9-c4bc-4b03-eb9d-23c739f24e51"
      },
      "source": [
        "! pip install textacy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textacy in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.19.5)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.62.3)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (3.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.22.2.post1)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.8.9)\n",
            "Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.11.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (8.0.13)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.6.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.8.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG0P2K-rxW-b",
        "outputId": "c3663bac-384e-45b6-c054-c399072e7c6f"
      },
      "source": [
        "! git clone https://github.com/MohamedISSA98/simple-but-tough-to-beat-examples.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simple-but-tough-to-beat-examples'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 12 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ7ZU0KJxb3S"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/simple-but-tough-to-beat-examples\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg72ZSuXw7UU"
      },
      "source": [
        "import encoder"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDO6HNRxwWR3"
      },
      "source": [
        "import csv\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from encoder import build_from_fasttext_bin\n",
        "from nn import train_w2v, train_nn, load_model, fasttext\n",
        "from utils import preprocess_sentence"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqEH6jSwWR5"
      },
      "source": [
        "Download the dataset (from github)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKzpHoOYwWR5",
        "outputId": "1e951732-76ab-4d1f-dc93-49ad9ce47cf6"
      },
      "source": [
        "CSV_FILE = 'fake_or_real_news.csv'\n",
        "\n",
        "! [[ ! -f { CSV_FILE } ]] && wget https://github.com/saadarshad102/Fake-News-Detection-Universal-Sentence-Encoder/raw/master/{ CSV_FILE }\n",
        "    \n",
        "def read_news(fname):\n",
        "    X = []\n",
        "    y = []\n",
        "    with open(fname) as f:\n",
        "        for row_num, row in enumerate(csv.reader(f)):\n",
        "            if row_num == 0:\n",
        "                continue\n",
        "            _, title, text, label = row\n",
        "            X.append(text)\n",
        "            y.append(label)\n",
        "    return X, y\n",
        "\n",
        "X, y = read_news(CSV_FILE)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-14 20:47:16--  https://github.com/saadarshad102/Fake-News-Detection-Universal-Sentence-Encoder/raw/master/fake_or_real_news.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/saadarshad102/Fake-News-Detection-Universal-Sentence-Encoder/master/fake_or_real_news.csv [following]\n",
            "--2021-11-14 20:47:17--  https://raw.githubusercontent.com/saadarshad102/Fake-News-Detection-Universal-Sentence-Encoder/master/fake_or_real_news.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30696129 (29M) [text/plain]\n",
            "Saving to: ‘fake_or_real_news.csv’\n",
            "\n",
            "fake_or_real_news.c 100%[===================>]  29.27M   139MB/s    in 0.2s    \n",
            "\n",
            "2021-11-14 20:47:17 (139 MB/s) - ‘fake_or_real_news.csv’ saved [30696129/30696129]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni5DxaS6wWR6"
      },
      "source": [
        "Build a corpus for word2vec training and pre-process with `textacy` lib:\n",
        "  - normalize unicode charset.\n",
        "  - deaccent (rèsume -> resume)\n",
        "  - unpack contractions (he's --> he is).\n",
        "  - remove emojis, hashtags, URLs, emails, etc\n",
        "  - remove punctuation marks\n",
        "  - strip whitespace\n",
        "  - lowercase\n",
        "  \n",
        "and train word2vec skipgram model as follows;\n",
        "  - dim = 200\n",
        "  - lr = relatively low.\n",
        "  - epochs = 15 (but should probably be ~ 25).\n",
        "  - ws = 5 (but should probably be ~ 7).\n",
        "  - sub-word information (minn = 3, maxn = 6).\n",
        "  \n",
        "alternatively, we can use a [pre-built model](https://fasttext.cc/docs/en/pretrained-vectors.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSN91hqLwWR6",
        "outputId": "ab510484-6025-4789-c228-c2e1e5d1fa61"
      },
      "source": [
        "W2V_PREBUILT_MODEL = 'cc.en.300.bin'\n",
        "W2V_MODEL = W2V_PREBUILT_MODEL # W2V_PREBUILT_MODEL\n",
        "\n",
        "if W2V_MODEL == W2V_PREBUILT_MODEL:\n",
        "    ! [[ ! -f {W2V_PREBUILT_MODEL} ]] && wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/{W2V_PREBUILT_MODEL}.gz\n",
        "    ! [[ ! -f {W2V_PREBUILT_MODEL} ]] && gzip -d {W2V_PREBUILT_MODEL}.gz\n",
        "    ! ls -lh {W2V_PREBUILT_MODEL}\n",
        "\n",
        "model = fasttext.load_model(W2V_MODEL)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-14 20:47:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  30.0MB/s    in 2m 24s  \n",
            "\n",
            "2021-11-14 20:49:54 (29.8 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "-rw-r--r-- 1 root root 6.8G Jan 18  2019 cc.en.300.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjgJJcF5wWR7"
      },
      "source": [
        "word2vec ---> \"Simple But Tough to Beat ..\" encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4SJsM2AwWR7"
      },
      "source": [
        "sentence_encoder = build_from_fasttext_bin(model, preprocessor=preprocess_sentence, weighted=True)\n",
        "\n",
        "del model # free some memory !"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcE4w0rx31j3",
        "outputId": "32fb1bed-db37-4677-dbca-425379c8f35d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = sentence_encoder.fit_transform(X_train)\n",
        "X_test = sentence_encoder.transform(X_test)\n",
        "\n",
        "print('X_train.shape = ', X_train.shape)\n",
        "print('X_test.shape = ', X_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape =  (5068, 300)\n",
            "X_test.shape =  (1267, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRLun7DZwWR8"
      },
      "source": [
        "Split train/test and transform sentences to their embedding representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwhTStMZwWR9"
      },
      "source": [
        "Now we can train a binary classification net:\n",
        "  - 1 hidden layer (128).\n",
        "  - dropout ~ [0.2 - 0.5].\n",
        "  - binary logloss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN39zq_rwWR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55b1984-2695-4b45-9283-4e9e971dd830"
      },
      "source": [
        "MODEL_PT = 'model.h5'\n",
        "\n",
        "model = train_nn(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    hidden_layers=(128,),\n",
        "    activation='relu',\n",
        "    dropout=0.4,\n",
        "    epochs=25,\n",
        "    batch_size=32,\n",
        "    # validation_split=0.1,\n",
        "    validation_data=(X_test, y_test),\n",
        "    patience=4,\n",
        "    shuffle=True,\n",
        "    optimizer='adam',\n",
        "    pt=MODEL_PT,\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "159/159 [==============================] - 4s 6ms/step - loss: 0.6286 - accuracy: 0.7399 - val_loss: 0.5318 - val_accuracy: 0.7932\n",
            "Epoch 2/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.7954 - val_loss: 0.4216 - val_accuracy: 0.8279\n",
            "Epoch 3/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8270 - val_loss: 0.3689 - val_accuracy: 0.8540\n",
            "Epoch 4/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8491 - val_loss: 0.3387 - val_accuracy: 0.8635\n",
            "Epoch 5/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.3416 - accuracy: 0.8625 - val_loss: 0.3181 - val_accuracy: 0.8706\n",
            "Epoch 6/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.8725 - val_loss: 0.3042 - val_accuracy: 0.8777\n",
            "Epoch 7/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.3072 - accuracy: 0.8814 - val_loss: 0.2945 - val_accuracy: 0.8777\n",
            "Epoch 8/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2969 - accuracy: 0.8816 - val_loss: 0.2867 - val_accuracy: 0.8777\n",
            "Epoch 9/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2863 - accuracy: 0.8867 - val_loss: 0.2804 - val_accuracy: 0.8848\n",
            "Epoch 10/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2821 - accuracy: 0.8887 - val_loss: 0.2756 - val_accuracy: 0.8863\n",
            "Epoch 11/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.8976 - val_loss: 0.2724 - val_accuracy: 0.8863\n",
            "Epoch 12/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2706 - accuracy: 0.8944 - val_loss: 0.2729 - val_accuracy: 0.8879\n",
            "Epoch 13/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2646 - accuracy: 0.8964 - val_loss: 0.2666 - val_accuracy: 0.8871\n",
            "Epoch 14/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2629 - accuracy: 0.8964 - val_loss: 0.2649 - val_accuracy: 0.8879\n",
            "Epoch 15/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2561 - accuracy: 0.8996 - val_loss: 0.2629 - val_accuracy: 0.8903\n",
            "Epoch 16/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2540 - accuracy: 0.9019 - val_loss: 0.2626 - val_accuracy: 0.8895\n",
            "Epoch 17/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2507 - accuracy: 0.9039 - val_loss: 0.2606 - val_accuracy: 0.8919\n",
            "Epoch 18/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2453 - accuracy: 0.9053 - val_loss: 0.2588 - val_accuracy: 0.8958\n",
            "Epoch 19/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2435 - accuracy: 0.9077 - val_loss: 0.2580 - val_accuracy: 0.8942\n",
            "Epoch 20/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2455 - accuracy: 0.9043 - val_loss: 0.2570 - val_accuracy: 0.8950\n",
            "Epoch 21/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9065 - val_loss: 0.2549 - val_accuracy: 0.8982\n",
            "Epoch 22/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2390 - accuracy: 0.9057 - val_loss: 0.2562 - val_accuracy: 0.8911\n",
            "Epoch 23/25\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9090 - val_loss: 0.2539 - val_accuracy: 0.8982\n",
            "Epoch 24/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2319 - accuracy: 0.9094 - val_loss: 0.2554 - val_accuracy: 0.8934\n",
            "Epoch 25/25\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2305 - accuracy: 0.9106 - val_loss: 0.2528 - val_accuracy: 0.8958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd7VrEivwWR9"
      },
      "source": [
        "91% accuracy with a pretty simple encoder ! that's nice !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqPSNnzewWR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89947f0-99dc-4476-fce6-436c6e6f93fd"
      },
      "source": [
        "model = load_model(MODEL_PT)\n",
        "preds = model.predict_classes(X_test, batch_size=32)\n",
        "preds = preds.reshape(preds.shape[0])\n",
        "\n",
        "report = classification_report(y_test, preds, target_names=label_encoder.classes_)\n",
        "print(report)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.90      0.89      0.89       628\n",
            "        REAL       0.89      0.90      0.90       639\n",
            "\n",
            "    accuracy                           0.90      1267\n",
            "   macro avg       0.90      0.90      0.90      1267\n",
            "weighted avg       0.90      0.90      0.90      1267\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:454: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ]
        }
      ]
    }
  ]
}